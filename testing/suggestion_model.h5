import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import os

# Check current working directory
print(f"Current working directory: {os.getcwd()}")

# Load Dataset
import json

# Make sure to handle file not found errors
try:
    with open('data.json', 'r') as file:
        data = json.load(file)
except FileNotFoundError:
    print("Error: data.json not found in the current directory!")
    exit(1)

# Convert to DataFrame
df = pd.DataFrame(data)

# Preprocessing
mlb_genre = MultiLabelBinarizer()
genre_encoded = mlb_genre.fit_transform(df['Genre'])
df_genre = pd.DataFrame(genre_encoded, columns=mlb_genre.classes_)
df = pd.concat([df, df_genre], axis=1)

# Encode categorical fields
emotion_mapping = {label: idx for idx, label in enumerate(df['Emotion'].unique())}
mood_mapping = {label: idx for idx, label in enumerate(df['Mood'].unique())}

# Map emotions and moods to numeric values
df['Emotion'] = df['Emotion'].map(emotion_mapping)
df['Mood'] = df['Mood'].map(mood_mapping)

# Save mappings for later use
import pickle
with open('genre_encoder.pkl', 'wb') as f:
    pickle.dump(mlb_genre, f)
with open('emotion_mapping.pkl', 'wb') as f:
    pickle.dump(emotion_mapping, f)
with open('mood_mapping.pkl', 'wb') as f:
    pickle.dump(mood_mapping, f)

# Feature and Target Split
X = df[df_genre.columns.tolist() + ['Emotion', 'Mood']]
y = pd.get_dummies(df['Title'])  # Target is the title (one-hot encoded)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build TensorFlow Model
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dense(y_train.shape[1], activation='softmax')  # Output layer
])

# Compile Model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train Model
history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))

# Print output shape
print(f"Model output shape: {model.output_shape}")
print(f"Number of movie titles: {y.shape[1]}")

# Save Model - make sure we're using the right path
try:
    model_path = 'suggestion_model.h5'
    model.save(model_path)
    print(f"Model saved successfully to {os.path.abspath(model_path)}")
except Exception as e:
    print(f"Error saving model: {e}")

# Verification step
print("Verifying if the model file exists:")
if os.path.exists('suggestion_model.h5'):
    print("  ✅ Model file exists")
    print(f"  File size: {os.path.getsize('suggestion_model.h5')} bytes")
else:
    print("  ❌ Model file does not exist!")

# Prediction Function
def recommend(content_features, model, mlb_genre, emotion_mapping, mood_mapping, title_columns):
    user_input = np.zeros((1, X.shape[1]))
    user_input[0, :-2] = mlb_genre.transform([content_features['Genre']])[0]
    user_input[0, -2] = emotion_mapping[content_features['Emotion']]
    user_input[0, -1] = mood_mapping[content_features['Mood']]
    
    predictions = model.predict(user_input)
    recommended_index = np.argmax(predictions)
    return title_columns[recommended_index]

# Example Usage
example_input = {
    "Genre": ["Animation"],
    "Emotion": "Exciting",
    "Mood": "Fun"  # Make sure this exists in your data
}

# Test the recommendation with sample input
try:
    recommendation = recommend(example_input, model, mlb_genre, emotion_mapping, mood_mapping, y.columns)
    print(f"Recommended Title: {recommendation}")
except Exception as e:
    print(f"Error during recommendation test: {e}")